<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Causal Inference in Natural Language</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
		<script type="text/javascript" src="http://livejs.com/live.js"></script>
	==
	</head>
	<body class="is-preload">

		<!-- Sidebar -->
			<section id="sidebar">
				<div class="inner">
					<nav>
						<ul>
							<li><a href="#intro">Project</a></li>
							<li><a href="#paper">Paper</a></li>
							<li><a href="#tasks">Tasks</a></li>
							<li><a href="#model">Model</a></li>
							<li><a href="#one">Team</a></li>
							<li><a href="#three">Acknowledgements</a></li>
						</ul>
					</nav>
				</div>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- -->
					<section id="intro" class="wrapper style1 fullscreen fade-up">
						<div class="inner">
							<h1>Challenges and an Empirical Evaluation Framework for Causal Inference with Natural Language</h1>
							<p> Using natural language, such as text, for causal inference has enormous potential for impactful
							research in computational social science and other domains.</p>

							<p>The Fundamental Problem of Cuasal Inference is that we can never observe the counterfactual, and so for a given observation
							in a study, we can only ever know the outcome in the treated case <i>or</i> the untreated case &mdash; never both.</p>

							<p>In observational studies, propensity scores can be used to estimate the counterfactual and adjust for observed confounders.
							When doing so with natural language, which is unstructured and extremely high dimensional, the challenge is to build a
							propensity score model that is effective at recovering confounders and covariates.
							However, evaluating these natural language propensity score models is extremely challenging,
							as ground truth causal effects are few and far between.
							</p>

							<p>In this work, we present a series of 6 tasks which together compose a principled empirical evaluation 
							framework for causal inference in natural langauge.</p>
							<!-- <p class =>However, such notebooks have remained
								largely unanalyzed at scale, as labels are absent and require
								expert domain knowledge to generate. We present a new classification
								task for labeling computational notebook cells as stages in
								the data analysis process (i.e., data import, wrangling, exploration,
								modeling, and evaluation).</p> -->

							<h2>What do we contribute?</h2>
							<div class="features">
								<section>
									<img  class="icon major" src="images/noun_task.svg" alt="Task">
									<h3><a href="#tasks">Six Evaluation Tasks</a></h3>
									<p>Our primary contribution is a series of six tasks, inspired by real challenges in natural language.
									Each task has a series of levels in increasing difficulty, allowing us to evaluate the specific strengths
									and weaknesses of different models.</p>
								</section>
								<section>
									<img  class="icon  major" src="images/noun_Deep Learning.svg" alt="Nueral Network">
									<h3><a href="#model">SHERBERT Model</a></h3>
									<p>SHERBERT is a novel cauSal HiERarchical variant of BERT, which effectively scales to long text inputs
									by using multiple pre-trained BERT models to produce an intermediate embedding.</p>
								</section>
								
								<!-- <section>
									<span class="icon solid major fa-cog"></span>
									<h3>Sed erat ullam corper</h3>
									<p>Phasellus convallis elit id ullam corper amet et pulvinar. Duis aliquam turpis mauris, sed ultricies erat dapibus.</p>
								</section>
								<section>
									<span class="icon solid major fa-desktop"></span>
									<h3>Veroeros quis lorem</h3>
									<p>Phasellus convallis elit id ullam corper amet et pulvinar. Duis aliquam turpis mauris, sed ultricies erat dapibus.</p>
								</section>
								<section>
									<span class="icon solid major fa-link"></span>
									<h3>Urna quis bibendum</h3>
									<p>Phasellus convallis elit id ullam corper amet et pulvinar. Duis aliquam turpis mauris, sed ultricies erat dapibus.</p>
								</section>
								<section>
									<span class="icon major fa-gem"></span>
									<h3>Aliquam urna dapibus</h3>
									<p>Phasellus convallis elit id ullam corper amet et pulvinar. Duis aliquam turpis mauris, sed ultricies erat dapibus.</p>
								</section> -->
							</div>
							<ul class="actions">
								<li><a href="#paper" class="button scrolly">Research Paper</a></li>
							</ul>
						</div>
					</section>
				<!-- Paper -->
				<section id="paper" class="wrapper style2 fade-up">
					<div class="inner">
						<h2>Paper (pre-print available on arXiv)</h2>
						<h3><a href=https://arxiv.org/pdf/2009.09961.pdf>[PDF]</a></h3>
						<p><b>Abstract:</b> Leveraging text, such as social media posts,
						for causal inferences requires the use of NLP
						models to ‘learn’ and adjust for confounders,
						which could otherwise impart bias. However, evaluating such models is challenging,
						as ground truth is almost never available. We
						demonstrate the need for empirical evaluation
						frameworks for causal inference in natural language by showing that existing, commonly
						used models regularly disagree with one another on real world tasks. We contribute
						the first such framework, generalizing several
						challenges across these real world tasks. Using this framework, we evaluate a large set
						of commonly used causal inference models
						based on propensity scores and identify their
						strengths and weaknesses to inform future improvements. We make all tasks, data, and models public to inform applications and encourage additional research. </p>
					</div>
				</section>
				<!-- Data -->
				<section id="tasks" class="wrapper style3 fade-up">
					<div class="inner">
						<h2>Tasks</h2>
						<p>All code used for this publication, and datasets for each task, are available on <a href='https://github.com/behavioral-data/CausalInferenceChallenges'><i class="fab fa-github"></i> GitHub</a>.</p>
						<p>Each task is designed to evaluate a model's ability to handle one of 6 different challenges in natural language.
						Tasks have multiple levels of difficulty, allowing us to see how models perform at handling each challenge.</p>
						<p>Tasks consist of semi-synthetic data, generated by inserting synthetic comments into real reddit users' post histories
							according to a known probability distribution, allowing us to control the true ATE, and therefore empirically evaluate the bias of each model on each task.
							Semi-synthetic data provides the best of both worlds: the realism of real world data, with the principled structure and known ATE of synthetic data.
						</p>
						<p>A description of each task is below. For more details, refer to the paper.</p>
						<div class="features">
							<section>
								<span class="icon solid major fa-code"></span>
								<h3>Linguistic Complexity</h3>
								<p>Models should be able to recognize the mutual importance of different phrases.</p>
							</section>
							<section>
								<span class="icon solid major fa-code"></span>
								<h3>Signal Intensity</h3>
								<p>Models should be able to detect weak signals.</p>
							</section>
							<section>
								<span class="icon solid major fa-code"></span>
								<h3>Order of Text</h3>
								<p>Models should be able to distinguish between the order of posts.</p>
							</section>
							<section>
								<span class="icon solid major fa-code"></span>
								<h3>Strength of Selection Effect</h3>
								<p>Models should be able to adjust for confounding, even when there is reduced overlap in the distribution of language between treated and untreated users.</p>
							</section>
							<section>
								<span class="icon solid major fa-code"></span>
								<h3>Number of Users</h3>
								<p>Models would be able to perform well even with limited training data.</p>
							</section>
							<section>
								<span class="icon major fa-code"></span>
								<h3>Absence of Non-Zero Treatment Effect</h3>
								<p>Models should not predict causality when none is present.</p>
							</section>
						</div>
					</div>
				</section>

				<!-- <section id="model" class="wrapper style1 fade-up">
					<div class="inner">
						<h2>SHERBERT Model</h2>
						<img class="image" src="images/SHERBERT.png" alt="Diagram of SHERBERT Model"> 
						<p>Our implementation of the SHERBERT model is available on <a href='https://github.com/behavioral-data/CausalInferenceChallenges'><i class="fab fa-github"></i> GitHub</a>.</p>
						<p>SHERBERT is a novel cauSal HiERarchical variant of BERT, which effectively scales to long text inputs
							by using multiple pre-trained BERT models to produce an intermediate embedding. </p>
					</div>
				</section> -->

				<section id="model" class="wrapper style2 spotlights">
					<section>
						<a href="#" class="image"><img src="images/SHERBERT_padded.png" alt="Diagram of SHERBERT Model" data-position="center center" /></a>
						<div class="content">
							<div class="inner">
								<h2>SHERBERT Model</h2>
								<p>Our implementation of the SHERBERT model is available on <a href='https://github.com/behavioral-data/CausalInferenceChallenges'><i class="fab fa-github"></i> GitHub</a>.</p>
								<p>SHERBERT is a novel cauSal HiERarchical variant of BERT, which effectively scales to long text inputs
								by using multiple pre-trained BERT models to produce an intermediate embedding. </p>
							</div>
						</div>
					</section>
				</section>


				<!-- One -->
				<section id="one" class="wrapper style2 spotlights">
					<div class="inner">
					<h2>Team</h2>
						<section>
							<div class = "row">
								<div class="col-6-xlarge col-6-large col-6-medium text-center">
									<img class="headshot" src="images/galen.jpg" alt="Galen Weld">
									<h3><a href="https://www.galenweld.com/">Galen Weld</a>
									</h3>
								</div>
								<div class=" col-6-xlarge col-6-large col-6-medium text-center">
									<img class="headshot" src="images/peter.jpg" alt="Peter West">
									<h3><a href="https://homes.cs.washington.edu/~pawest/">Peter West</a>
									</h3>
								</div>
								<div class=" col-6-xlarge col-6-large col-6-medium text-center">
									<img class="headshot" src="images/maria.jpg" alt="Maria Glenski">
									<h3><a href="https://www.pnnl.gov/people/maria-glenski">Maria Glenski</a>
									</h3>
								</div>
							</div>
						</section>
						<section>
							<div class = "row">
								<div class="col-4-large col-4-xlarge  text-center">
									<img class="headshot" src="images/david.jpg" alt="David Arbour">
									<h3><a href="http://darbour.github.io/">David Arbour</a>
									</h3>
								</div>
								<div class="col-4-large col-4-xlarge text-center">
									<img class=" headshot" src="images/ryan.png" alt="Ryan A. Rossi">
									<h3><a href="http://ryanrossi.com/">Ryan A. Rossi</a>
									</h3>
								</div>
								<div class="col-4-large col-4-xlarge text-center">
									<img class=" headshot" src="images/tim.jpg" alt="Tim Althoff"> 
									<h3><a href="http://www.timalthoff.com/" target="_new">Tim Althoff</a>

									</h3>
								</div>
							</div>
						</section>
					</div>
				</section>

				

				<!-- Three -->
					<section id="three" class="wrapper style1 fade-up">
						<div class="inner">
							<h2>Acknowledgements</h2>
							<p>We would like to thank Adobe Research for their support of this work.</p>
						</div>
					</section>

			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper style1-alt">
				<div class="inner">
					<ul class="menu">
						<li>&copy; Galen Weld. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>