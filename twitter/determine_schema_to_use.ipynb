{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README\n",
    "\n",
    "In this notebook, we'll open up the old `posts.npy` file and take a look and what schema we should use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = np.load('reddit_posts.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(posts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'badfishsmells'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(posts[0].keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts[0]['badfishsmells'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(posts[0]['badfishsmells'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subreddit': 'Romania',\n",
       " 'score': 2,\n",
       " 'link_id': 't3_35q42z',\n",
       " 'removal_reason': None,\n",
       " 'subreddit_id': 't5_2qm35',\n",
       " 'distinguished': None,\n",
       " 'archived': False,\n",
       " 'controversiality': 0,\n",
       " 'retrieved_on': 1433047337,\n",
       " 'name': 't1_cr870ap',\n",
       " 'edited': False,\n",
       " 'created_utc': '1431552016',\n",
       " 'author_flair_css_class': None,\n",
       " 'downs': 0,\n",
       " 'ups': 2,\n",
       " 'author_flair_text': None,\n",
       " 'score_hidden': False,\n",
       " 'gilded': 0,\n",
       " 'author': 'badfishsmells',\n",
       " 'parent_id': 't1_cr6zmi8',\n",
       " 'body': 'Poate alte articole scrie bine, poate se documenteaza. In asta a fost doar marlan. Si nu poti sa fii cateodata marlan, cateodata decent. Sau ai etica jurnalistica sau nu. Sau iti argumentezi opiniile sau esti soiul \"ala\" de taximetrist.\\n\\nOr, daca faci glume, fa-le intr-un context in care sa se inteleaga ca sunt glume, nu faci un articol plin de insulte si astepti lumea sa te aplaude. Oamenii au reactionat cum era de asteptat, l-au banat si gata. Si mi se pare normal, cyber bully, troll sau ce alt fel de kkt cu ochi care arunca opinii si doar atat, trebuie banat dupa mine. \\n\\nInteleg ca unii mai gresesc, si isi cer scuze dupa. Asta insa se mandreste cu ce face, pana nu il da in judecata careva, sa vezi cum se potoleste (sau o da pe victima cenzurii etc.).\\n\\nTLDR: E usor sa te doara\\'n pula de tot. E greu sa fii selectiv cu durutu. ',\n",
       " 'id': 'cr870ap'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts[0]['badfishsmells'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion\n",
    "\n",
    "the `posts.npy` file is minimally preprocessed, it just is an array wrapping a big dict\n",
    "\n",
    "that dict maps usernames to lists of posts, where each post is a dict created straight from reddit json dumps,\n",
    "the only fields I think we use from this is `'body'`\n",
    "\n",
    "tokenize happens downstream  and just uses NLTK's word_tokenize so I won't mess with that\n",
    "\n",
    "seems like all I should do is group the twitter users by their authors and save that as a dict where each author is a key and maps to a list of at least 10 and less than 60 posts, each post being a dict with a 'body' key and associated value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:reddit_moderation]",
   "language": "python",
   "name": "conda-env-reddit_moderation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
