{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from requests_oauthlib import OAuth1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load API access tokens\n",
    "from SECRET_DO_NOT_PUBLISH import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuth1(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using count=60 to limit to at most 60 tweets, as in the main paper\n",
    "\n",
    "endpoint = 'https://api.twitter.com/1.1/statuses/user_timeline.json?screen_name={}&count=60&tweet_mode=extended&trim_user=true'\n",
    "\n",
    "# EXPLANATION OF PARAMS\n",
    "# screen_name : user to fetch\n",
    "# count       : number of tweets to limit to (max 200)\n",
    "# tweet_mode  : need this to return non-truncated tweets\n",
    "# trim_user   : don't need to return the complete users' details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history(screen_name):\n",
    "    response = requests.get(endpoint.format(screen_name), auth=auth)\n",
    "    \n",
    "#     if response.status_code != 200:\n",
    "\n",
    "    response.raise_for_status()\n",
    "        \n",
    "    \n",
    "    # parse out just the text of the posts\n",
    "    return [{'body' : post['full_text']} for post in response.json()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load users to request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9,817 usernames from file.\n"
     ]
    }
   ],
   "source": [
    "users_to_request = []\n",
    "\n",
    "with open('random_users_full.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    \n",
    "    for row in reader:\n",
    "        users_to_request.append( row[0] )\n",
    "        \n",
    "print(f'Loaded {len(users_to_request):,d} usernames from file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING MODE: ignoring most users\n"
     ]
    }
   ],
   "source": [
    "TESTING_MODE = False\n",
    "\n",
    "if TESTING_MODE:\n",
    "    users_to_request = users_to_request[:20]\n",
    "    print('TESTING MODE: ignoring most users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0001 / 0020] Requesting history for Nik____ka...         wrote 60 tweets to file.\n",
      "[0002 / 0020] Requesting history for EmbraceMeHere...     wrote 60 tweets to file.\n",
      "[0003 / 0020] Requesting history for realmattcooke...     wrote 60 tweets to file.\n",
      "[0004 / 0020] Requesting history for ItsTexasT03...       Error!\n",
      "\n",
      "401 Client Error: Authorization Required for url: https://api.twitter.com/1.1/statuses/user_timeline.json?screen_name=ItsTexasT03&count=60&tweet_mode=extended&trim_user=true\n",
      "\n",
      "[0005 / 0020] Requesting history for CjWilson850...       wrote 60 tweets to file.\n",
      "[0006 / 0020] Requesting history for TotalTrafficSEA...   wrote 60 tweets to file.\n",
      "[0007 / 0020] Requesting history for TheHobbySpyder...    Error!\n",
      "\n",
      "404 Client Error: Not Found for url: https://api.twitter.com/1.1/statuses/user_timeline.json?screen_name=TheHobbySpyder&count=60&tweet_mode=extended&trim_user=true\n",
      "\n",
      "[0008 / 0020] Requesting history for 35mmPapi...          wrote 60 tweets to file.\n",
      "[0009 / 0020] Requesting history for PoeticLicencedk...   wrote 59 tweets to file.\n",
      "[0010 / 0020] Requesting history for Denisemccaffer7...   Error!\n",
      "\n",
      "401 Client Error: Unauthorized for url: https://api.twitter.com/1.1/statuses/user_timeline.json?screen_name=Denisemccaffer7&count=60&tweet_mode=extended&trim_user=true\n",
      "\n",
      "[0011 / 0020] Requesting history for EvilMarsupials...    wrote 60 tweets to file.\n",
      "[0012 / 0020] Requesting history for JayHSalem...         Error!\n",
      "\n",
      "401 Client Error: Authorization Required for url: https://api.twitter.com/1.1/statuses/user_timeline.json?screen_name=JayHSalem&count=60&tweet_mode=extended&trim_user=true\n",
      "\n",
      "[0013 / 0020] Requesting history for deliveryguy6980...   Error!\n",
      "\n",
      "404 Client Error: Not Found for url: https://api.twitter.com/1.1/statuses/user_timeline.json?screen_name=deliveryguy6980&count=60&tweet_mode=extended&trim_user=true\n",
      "\n",
      "[0014 / 0020] Requesting history for Pup_Bellagio...      wrote 60 tweets to file.\n",
      "[0015 / 0020] Requesting history for AJGullotta...        wrote 60 tweets to file.\n",
      "[0016 / 0020] Requesting history for UhlirBeth...         wrote 60 tweets to file.\n",
      "[0017 / 0020] Requesting history for jwill9311...         wrote 60 tweets to file.\n",
      "[0018 / 0020] Requesting history for JoeHealey42...       wrote 60 tweets to file.\n",
      "[0019 / 0020] Requesting history for dazz0_716...         wrote 60 tweets to file.\n",
      "[0020 / 0020] Requesting history for jay_a_white_...      Error!\n",
      "\n",
      "404 Client Error: Not Found for url: https://api.twitter.com/1.1/statuses/user_timeline.json?screen_name=jay_a_white_&count=60&tweet_mode=extended&trim_user=true\n",
      "\n",
      "Finished in   0.01 hours. Saved 839 tweets from 14 users.\n",
      "Failed on 6 users.\n"
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "error_count   = 0\n",
    "tweet_count   = 0\n",
    "\n",
    "start_time    = time.monotonic()\n",
    "\n",
    "with open('twitter_posts.jsonl', 'w') as f, open('error_names.txt', 'w') as errorfile:\n",
    "    for i, screen_name in enumerate(users_to_request):\n",
    "        print(f'[{i+1:04d} / {len(users_to_request):04d}] Requesting history for {screen_name+\"...\":<20}', end='')\n",
    "        \n",
    "        try:\n",
    "            history = get_history(screen_name)\n",
    "            f.write( json.dumps({screen_name : history})+'\\n' )\n",
    "            print(f' wrote {len(history):02d} tweets to file.')\n",
    "            \n",
    "            success_count += 1\n",
    "            tweet_count   += len(history)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f' Error!')\n",
    "            print('')\n",
    "            print(e)\n",
    "            print('')\n",
    "            \n",
    "            errorfile.write(screen_name+'\\n')\n",
    "            \n",
    "            error_count += 1\n",
    "            \n",
    "        time.sleep(1)\n",
    "            \n",
    "print(f'Finished in {(time.monotonic()-start_time)/(60**2):6.2f} hours. Saved {tweet_count:,d} tweets from {success_count:,d} users.')\n",
    "print(f'Failed on {error_count:,d} users.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load and and resave posts as numpy\n",
    "\n",
    "now that we've finished scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8,927 histories from file. 507,113 tweets in total.\n"
     ]
    }
   ],
   "source": [
    "data       = {}\n",
    "num_tweets = 0\n",
    "\n",
    "with open('twitter_posts.jsonl') as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        \n",
    "        for screen_name, history in obj.items():\n",
    "            data[screen_name] = history\n",
    "            \n",
    "            num_tweets += len(history)\n",
    "\n",
    "print(f'Loaded {len(data):,d} histories from file. {num_tweets:,d} tweets in total.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered down to 8,764 histories with at least 10 tweets.\n",
      "506,378 tweets total.\n"
     ]
    }
   ],
   "source": [
    "data = {screen_name:history for screen_name, history in data.items() if len(history)>=10}\n",
    "print(f'Filtered down to {len(data):,d} histories with at least 10 tweets.')\n",
    "print(f'{sum([len(h) for h in data.values()]):,d} tweets total.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly sampled down to 8,000 histories.\n",
      "462,108 tweets total.\n"
     ]
    }
   ],
   "source": [
    "data = {screen_name:history for screen_name, history in random.sample(data.items(), k=8000)}\n",
    "print(f'Randomly sampled down to {len(data):,d} histories.')\n",
    "print(f'{sum([len(h) for h in data.values()]):,d} tweets total.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewrote posts to .npy format.\n"
     ]
    }
   ],
   "source": [
    "np.save('twitter_posts.npy', np.array( [data] ))\n",
    "print('Rewrote posts to .npy format.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posts = np.load('twitter_posts.npy', allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:reddit_moderation]",
   "language": "python",
   "name": "conda-env-reddit_moderation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
